{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n",
    "</a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Loss Function with a High Condition Number with and Without Momentum</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "<p>In this lab, we will generate data that will produce a Loss Function with a High Condition Number. You will create two models; one with the momentum term and one without the momentum term.</p>\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#Makeup_Data\">Make Some Data </a></li>\n",
    "    <li><a href=\"#Model_Cost\">Create two Models, Two Optimizers and a Cost Function</a></li>\n",
    "    <li><a href=\"#BGD\">Train the Model: Batch Gradient Descent</a></li>\n",
    "</ul>\n",
    "<p>Estimated Time Needed: <strong>30 min</strong></p>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need the following libraries:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we need for this lab\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class <code>plot_error_surfaces</code> is just to help you visualize the data space and the parameter space during training and has nothing to do with Pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class for plot out the surface\n",
    "\n",
    "class plot_error_surfaces(object):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, w_range, b_range, X, Y, n_samples=30, go=True):\n",
    "        W = np.linspace(-w_range, w_range, n_samples)\n",
    "        B = np.linspace(-b_range, b_range, n_samples)\n",
    "        w, b = np.meshgrid(W, B)    \n",
    "        Z = np.zeros((n_samples, n_samples))\n",
    "        count1 = 0\n",
    "        self.y = Y.numpy()\n",
    "        self.x = X.numpy()\n",
    "        for w1, b1 in zip(w, b):\n",
    "            count2 = 0\n",
    "            for w2, b2 in zip(w1, b1):\n",
    "                Z[count1, count2] = np.mean((self.y - w2 * self.x + b2) ** 2)\n",
    "                count2 += 1\n",
    "            count1 += 1\n",
    "        self.Z = Z\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.LOSS_list = {}\n",
    "    \n",
    "    # Setter\n",
    "    def set_para_loss(self, model, name, loss):\n",
    "        if (not (name in self.LOSS_list)):\n",
    "            self.LOSS_list[name] = []\n",
    "        w = list(model.parameters())[0].item()\n",
    "        b = list(model.parameters())[1].item()\n",
    "        self.LOSS_list[name].append({\"loss\": loss, \"w\": w, \"b\": b})\n",
    "        \n",
    "    # Plot the diagram\n",
    "    def plot_ps(self, iteration=0):\n",
    "        plt.contour(self.w, self.b, self.Z)\n",
    "        count = 1\n",
    "        if (len(self.LOSS_list) > 0):\n",
    "            for key, value in self.LOSS_list.items():\n",
    "                w = [v for d in value for (k, v) in d.items() if \"w\" == k]\n",
    "                b = [v for d in value for (k, v) in d.items() if \"b\" == k]\n",
    "                plt.scatter(w, b, cmap='viridis', marker='x', label=key)\n",
    "            plt.title('Loss Surface Contour not to scale, Iteration: ' + str(iteration))\n",
    "            plt.legend()\n",
    "        plt.xlabel('w')\n",
    "        plt.ylabel('b')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Makeup_Data\">Make Some Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate values from -2 to 2 that create a line with a slope of 0.1 and a bias of 10000. This is the line that you need to estimate. Add some noise to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to create the dataset\n",
    "\n",
    "class Data(Dataset):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        self.x = torch.arange(-2, 2, 0.1).view(-1, 1)\n",
    "        self.f = 1 * self.x + 10000\n",
    "        self.y = self.f + 0.1 * torch.randn(self.x.size())\n",
    "        self.len = self.x.shape[0]\n",
    "        \n",
    "    # Getter\n",
    "    def __getitem__(self, index):    \n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset object\n",
    "\n",
    "dataset = Data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "\n",
    "plt.plot(dataset.x.numpy(), dataset.y.numpy(), 'rx', label='y')\n",
    "plt.plot(dataset.x.numpy(), dataset.f.numpy(), label='f')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Model_Cost\">Create the Model and Total Loss Function (Cost)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a linear regression class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define linear regression class\n",
    "\n",
    "class linear_regression(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(linear_regression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        yhat = self.linear(x)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use PyTorch's build-in function to create a criterion function; this calculates the total loss or cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the build-in function to create a criterion function\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a linear regression object, and an SGD optimizer object with no momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression object and the optimizer without momentum\n",
    "\n",
    "model = linear_regression(1, 1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a linear regression object, and an SGD optimiser object with momentum ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression object and the optimizer with momentum\n",
    "\n",
    "model_momentum = linear_regression(1, 1)\n",
    "optimizer_momentum = optim.SGD(model_momentum.parameters(), lr=0.01, momentum=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataloader object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data loader\n",
    "\n",
    "trainloader = DataLoader(dataset=dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch randomly initializes your model parameters. If we use those parameters, the result will not be very insightful as convergence will be extremely fast. In order to prevent that, we will initialize the parameters such that it will take longer to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "\n",
    "model.state_dict()['linear.weight'][0] = -5000\n",
    "model.state_dict()['linear.bias'][0] = -100000\n",
    "model_momentum.state_dict()['linear.weight'][0] = -5000\n",
    "model_momentum.state_dict()['linear.bias'][0] = -100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a plotting object, not part of PyTorch, only used to help visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the surface\n",
    "\n",
    "get_surface = plot_error_surfaces(5000, 100000, dataset.x, dataset.y, 100, go=False)\n",
    "get_surface.plot_ps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"BGD\">Train the Model via Stochastic Gradient Descent</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 1 epochs of stochastic gradient descent and view parameter space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "def train_model(epochs=1):\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(trainloader):\n",
    "            #no momentum\n",
    "            yhat = model(x)\n",
    "            loss = criterion(yhat, y)\n",
    "\n",
    "            #momentum\n",
    "            yhat_m = model_momentum(x)\n",
    "            loss_m = criterion(yhat_m, y)\n",
    "\n",
    "            #apply optimization to momentum term and term without momentum \n",
    "\n",
    "            #for plotting \n",
    "            #get_surface.get_stuff(model, loss.tolist())\n",
    "            #get_surface.get_stuff1(model_momentum, loss_m.tolist())\n",
    "\n",
    "            get_surface.set_para_loss(model=model_momentum, name=\"momentum\" ,loss=loss_m.tolist())\n",
    "            get_surface.set_para_loss(model=model, name=\"no momentum\" , loss=loss.tolist())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            optimizer_momentum.zero_grad()\n",
    "            loss.backward()\n",
    "            loss_m.backward()\n",
    "            optimizer.step()\n",
    "            optimizer_momentum.step()\n",
    "        get_surface.plot_ps(iteration=i)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows the different parameter values for each model in different iterations of SGD. The values are overlaid over the cost or total loss surface. The contour lines somewhat miss scaled but it is evident that in the vertical direction they are much closer together implying a larger gradient in that direction. The model trained with momentum shows somewhat more displacement in the hozontal direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows the log of the cost or total loss, we see that the term with momentum converges to a minimum faster and to an overall smaller value. We use the log to make the difference more evident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss\n",
    "\n",
    "loss = [v for d in get_surface.LOSS_list[\"no momentum\"] for (k, v) in d.items() if \"loss\" == k]\n",
    "loss_m = [v for d in get_surface.LOSS_list[\"momentum\"] for (k, v) in d.items() if \"loss\" == k]\n",
    "plt.plot(np.log(loss), 'r', label='no momentum' )\n",
    "plt.plot(np.log(loss_m), 'b', label='momentum' )\n",
    "plt.title('Cost or Total Loss' )\n",
    "plt.xlabel('Iterations ')\n",
    "plt.ylabel('Cost')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_bottom\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/notebook_bottom%20.png\" width=\"750\" alt=\"PyTorch Bottom\" />\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
